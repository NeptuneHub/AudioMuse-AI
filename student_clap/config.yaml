distillation:
  audio_enabled: true
  text_enabled: false
audio:
  sample_rate: 48000
  segment_length: 480000
  hop_length: 240000
  n_mels: 128
  n_fft: 2048
  hop_length_stft: 480
  fmin: 0
  fmax: 14000

model:
  embedding_dim: 512
  # PhiNet 3 configuration (tinyCLAP: alpha=3.0, beta=0.75, t0=4, N=7 → 4M+ params)
  # PhiNet NEW1 configuration (tinyCLAP: alpha=3.0, beta=0.75, t0=6, N=8 → 8M+ params)

  phinet_alpha: 3.0
  phinet_beta: 0.75
  phinet_t0: 4
  phinet_N: 7
  hidden_dim: 256
  dropout: 0.1
  use_gradient_checkpointing: true
  segment_batch_size: 5  # Process N segments at a time to reduce memory

model_text:
  embedding_dim: 512
  hidden_dim: 256
  num_layers: 2
  nhead: 4

training:
  batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 0.00003 # Original: 0.003
  epochs: 100
  stage2_epochs: 10
  stage2_learning_rate: 0.000003
  projection_only: false
  optimizer: "adamw"
  weight_decay: 0.1
  grad_clip: 1.0
  training_strategy: "both"
  save_every: 1
  early_stopping_patience: 10
  validation_split: 0.15
  # Loss scaling options
  loss_temperature: 1.5       # Static temperature (divide cosine by this value). If using logit scale, set use_logit_scale=True
  use_logit_scale: false      # If true, use a learnable logit_scale (exp(logit_scale) applied to cosine)
  init_logit_scale: 1.0       # Initial value for learnable logit_scale (only used if use_logit_scale=True)
  # Focal-style weighting for cosine (set gamma>0 to enable)
  loss_focal_gamma: 2.0       # gamma > 0 focuses gradients on hard (low-cosine) samples
  loss_focal_low_threshold: 0.35  # cosine <= low -> full weight
  loss_focal_high_threshold: 0.60 # cosine >= high -> zero weight; interpolate between low and high
  lr_scheduler:
    mode: 'max'             # monitor metric to maximize (we monitor validation cosine)
    factor: 0.1             # LR reduction factor
    patience: 3             # Number of epochs with no improvement before reducing LR
    threshold: 0.005       # Minimum relative improvement to be considered as improvement
    threshold_mode: 'rel'   # 'rel' or 'abs'
    min_lr: 1e-6            # Minimum LR


paths:
  teacher_model: "../model/clap_audio_model.onnx"
  teacher_model_text: "../model/clap_text_model.onnx"
  mel_cache: "/Volumes/audiomuse/student_clap_cache/mel_spectrograms.db"
  checkpoints: "./checkpoints"
  logs: "./logs"
  final_model: "./models/student_clap_audio.onnx"
  final_model_text: "./models/final_text_model.onnx"
  text_json: "../model/text.json"

dataset:
  fma_path: "/Users/guidocolangiuli/Music/FMA"
  sample_size: 0

logging:
  level: "INFO"
  log_every: 10
