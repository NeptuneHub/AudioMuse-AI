audio:
  sample_rate: 48000
  segment_length: 480000
  hop_length: 240000
  n_mels: 128
  n_fft: 2048
  hop_length_stft: 480
  fmin: 0
  fmax: 14000

model:
  embedding_dim: 512
  cnn_channels: [32, 64, 128]
  transformer_layers: 2
  attention_heads: 4
  hidden_dim: 256
  dropout: 0.1

training:
  batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 0.012
  epochs: 30
  stage2_epochs: 10
  stage2_learning_rate: 0.004
  projection_only: false
  optimizer: "adam"
  weight_decay: 0.0
  grad_clip: 5.0
  training_strategy: "both"
  save_every: 1
  early_stopping_patience: 10
  validation_split: 0.15

paths:
  teacher_model: "../model/clap_audio_model.onnx"
  mel_cache: "/Volumes/audiomuse/student_clap_cache/mel_spectrograms.db"
  checkpoints: "./checkpoints"
  logs: "./logs"
  final_model: "./models/student_clap_audio.onnx"

dataset:
  fma_path: "/Users/guidocolangiuli/Music/FMA"
  sample_size: 0

logging:
  level: "INFO"
  log_every: 10
