distillation:
  audio_enabled: true
  text_enabled: false
audio:
  sample_rate: 48000
  segment_length: 480000
  hop_length: 240000
  n_mels: 128
  n_fft: 2048
  hop_length_stft: 480
  fmin: 0
  fmax: 14000

model:
  embedding_dim: 512
  # PhiNet 3 configuration (tinyCLAP: alpha=3.0, beta=0.75, t0=4, N=7 â†’ 6.2M params)
  phinet_alpha: 3.0
  phinet_beta: 0.75
  phinet_t0: 6
  phinet_N: 8
  hidden_dim: 256
  dropout: 0.1
  use_gradient_checkpointing: true
  segment_batch_size: 5  # Process N segments at a time to reduce memory

model_text:
  embedding_dim: 512
  hidden_dim: 256
  num_layers: 2
  nhead: 4

training:
  batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 0.003
  epochs: 100
  stage2_epochs: 10
  stage2_learning_rate: 0.001
  projection_only: false
  optimizer: "adam"
  weight_decay: 0.0
  grad_clip: 5.0
  training_strategy: "both"
  save_every: 1
  early_stopping_patience: 10
  validation_split: 0.15

paths:
  teacher_model: "../model/clap_audio_model.onnx"
  teacher_model_text: "../model/clap_text_model.onnx"
  mel_cache: "/Volumes/audiomuse/student_clap_cache/mel_spectrograms.db"
  checkpoints: "./checkpoints"
  logs: "./logs"
  final_model: "./models/student_clap_audio.onnx"
  final_model_text: "./models/final_text_model.onnx"
  text_json: "../model/text.json"

dataset:
  fma_path: "/Users/guidocolangiuli/Music/FMA"
  sample_size: 0

logging:
  level: "INFO"
  log_every: 10
