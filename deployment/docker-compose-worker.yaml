# AudioMuse-AI Deployment Configuration
#
# WORKER TEMPLATE - Run this for heavy CPU tasks like analysis and clustering, connected to a lightweight server with Jellyfin and AudioMuse-AI Flask application and databases.
version: '3.8'
services:
  # AudioMuse-AI Worker service (GPU-dependent)
  audiomuse-ai-worker:
    image: ghcr.io/neptunehub/audiomuse-ai:latest-nvidia
    container_name: audiomuse-ai-worker-instance
    runtime: nvidia  # Use nvidia runtime (older but reliable method)
    ports:
      - "8029:8000"  # Expose worker API
    environment:
      SERVICE_TYPE: "worker"
      MEDIASERVER_TYPE: "jellyfin"
      JELLYFIN_USER_ID: "YOUR-JF-USER-ID" #for example: 0e45c44b3e2e4da7a2be11a72a1c8575
      JELLYFIN_TOKEN: "YOUR-JF-TOKEN" # for example: e0b8c325bc1b426c81922b90c0aa2ff1
      JELLYFIN_URL: "YOUR-JF-URL" # for example: http://jellyfin.192.168.3.131.nip.io:8087
      POSTGRES_USER: "audiomuse"
      POSTGRES_PASSWORD: "audiomusepassword"
      POSTGRES_DB: "audiomusedb"
      POSTGRES_HOST: "YOUR_SERVER_IP" # Replace with the IP of the server hosting Postgres
      POSTGRES_PORT: "5432"
      REDIS_URL: "redis://YOUR_SERVER_IP:6379/0"  # Points to server hosting Redis, for example: redis://192.168.3.131:6379/0
      GEMINI_API_KEY: "YOUR_GEMINI_API_KEY_HERE"
      TEMP_DIR: "/app/temp_audio"
      NVIDIA_VISIBLE_DEVICES: "0"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    volumes:
      - temp-audio-worker:/app/temp_audio
    restart: unless-stopped

volumes:
  temp-audio-worker: