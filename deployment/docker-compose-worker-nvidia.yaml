# AudioMuse-AI Worker-Only Docker Compose (NVIDIA GPU)
# =============================================================================
# WORKER TEMPLATE - Runs RQ workers only with GPU acceleration
#
# Use this for split deployments where:
#   - Server (Flask + Redis + PostgreSQL) runs on separate machine
#   - This worker handles GPU-accelerated ML analysis tasks
#
# Prerequisites:
#   - Server running docker-compose-server.yaml on another machine
#   - Network connectivity to server (ports 6379 Redis, 5432 PostgreSQL)
#   - Access to same music files (via media server API or shared storage)
#   - NVIDIA GPU with docker nvidia-runtime installed
#
# Quick Start:
#   1. Copy .env.example to .env on this worker machine
#   2. Configure connection to remote server:
#        WORKER_REDIS_URL=redis://SERVER_IP:6379/0
#        WORKER_POSTGRES_HOST=SERVER_IP
#   3. Copy media server credentials from server's .env
#   4. Run: docker-compose -f docker-compose-worker-nvidia.yaml up -d
#
# Scaling:
#   - Run multiple workers on different machines
#   - All workers connect to same Redis queue
#   - Tasks automatically distributed across workers
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # AudioMuse-AI Worker (NVIDIA GPU, connects to remote server)
  # ---------------------------------------------------------------------------
  audiomuse-ai-worker:
    image: ghcr.io/neptunehub/audiomuse-ai:latest-nvidia
    container_name: audiomuse-ai-worker-nvidia
    environment:
      SERVICE_TYPE: "worker"
      TZ: "${TZ:-UTC}"
      # =======================================================================
      # REMOTE SERVER CONNECTION (REQUIRED)
      # =======================================================================
      # Redis URL - point to server machine
      # Format: redis://[password@]host:port/db
      # Examples:
      #   redis://192.168.1.100:6379/0
      #   redis://:mypassword@192.168.1.100:6379/0
      REDIS_URL: "${WORKER_REDIS_URL:-redis://redis:6379/0}"
      # PostgreSQL host - IP or hostname of server machine
      POSTGRES_HOST: "${WORKER_POSTGRES_HOST:-postgres}"
      POSTGRES_PORT: "${POSTGRES_PORT:-5432}"
      POSTGRES_USER: ${POSTGRES_USER:-audiomuse}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-audiomusepassword}
      POSTGRES_DB: ${POSTGRES_DB:-audiomusedb}
      # =======================================================================
      # MEDIA SERVER CONFIGURATION (must match server)
      # =======================================================================
      MEDIASERVER_TYPE: "${MEDIASERVER_TYPE:-localfiles}"
      JELLYFIN_URL: "${JELLYFIN_URL:-}"
      JELLYFIN_USER_ID: "${JELLYFIN_USER_ID:-}"
      JELLYFIN_TOKEN: "${JELLYFIN_TOKEN:-}"
      NAVIDROME_URL: "${NAVIDROME_URL:-}"
      NAVIDROME_USER: "${NAVIDROME_USER:-}"
      NAVIDROME_PASSWORD: "${NAVIDROME_PASSWORD:-}"
      LYRION_URL: "${LYRION_URL:-}"
      EMBY_URL: "${EMBY_URL:-}"
      EMBY_USER_ID: "${EMBY_USER_ID:-}"
      EMBY_TOKEN: "${EMBY_TOKEN:-}"
      LOCALFILES_MUSIC_DIRECTORY: "${LOCALFILES_MUSIC_DIRECTORY:-/music}"
      LOCALFILES_PLAYLIST_DIR: "${LOCALFILES_PLAYLIST_DIR:-/music/playlists}"
      # =======================================================================
      # AI CONFIGURATION (optional)
      # =======================================================================
      AI_MODEL_PROVIDER: "${AI_MODEL_PROVIDER:-NONE}"
      OPENAI_API_KEY: "${OPENAI_API_KEY:-}"
      OPENAI_SERVER_URL: "${OPENAI_SERVER_URL:-}"
      OPENAI_MODEL_NAME: "${OPENAI_MODEL_NAME:-}"
      GEMINI_API_KEY: "${GEMINI_API_KEY:-}"
      MISTRAL_API_KEY: "${MISTRAL_API_KEY:-}"
      # =======================================================================
      # WORKER FEATURES (GPU-enabled)
      # =======================================================================
      # CLAP text search - uses ~750MB RAM
      CLAP_ENABLED: "${CLAP_ENABLED:-true}"
      # GPU clustering - enabled for NVIDIA worker
      USE_GPU_CLUSTERING: "${USE_GPU_CLUSTERING:-true}"
      # Worker tuning
      RQ_MAX_JOBS: "${RQ_MAX_JOBS:-50}"
      RQ_MAX_JOBS_HIGH: "${RQ_MAX_JOBS_HIGH:-100}"
      RQ_LOGGING_LEVEL: "${RQ_LOGGING_LEVEL:-INFO}"
      TEMP_DIR: "/app/temp_audio"
      # NVIDIA GPU settings
      NVIDIA_VISIBLE_DEVICES: "${NVIDIA_GPU_ID:-0}"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    volumes:
      - temp-audio-worker:/app/temp_audio
      # Mount music directory if using local files provider
      - ${MUSIC_PATH:-./music}:/music:ro
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${NVIDIA_GPU_ID:-0}"]
              capabilities: [gpu]

# =============================================================================
# Volumes
# =============================================================================
volumes:
  temp-audio-worker:
    name: audiomuse-temp-worker-nvidia
